{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center>欢迎来到LightGBM的世界</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mac下的编译安装"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### 命令如下：\n",
    "\n",
    "brew install cmake\n",
    "\n",
    "brew install gcc --without-multilib\n",
    "\n",
    "\n",
    "git clone --recursive https://github.com/Microsoft/LightGBM\n",
    "\n",
    "cd LightGBM\n",
    "\n",
    "export CXX=g++-7 CC=gcc-7\n",
    "\n",
    "mkdir build\n",
    "\n",
    "cd build\n",
    "\n",
    "cmake ..\n",
    "\n",
    "make -j4\n",
    "\n",
    "pip3 install lightgbm\n",
    "\n",
    "\n",
    "#### 温暖提示：\n",
    "\n",
    "cd python-package\n",
    "\n",
    "sudo python setup.py install \n",
    "\n",
    "会依然提示CMake没有安装的问题，至今不知道是为什么？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 读入原始数据，并进行数据集划分(数据集来源于官方网站)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train= pd.read_csv('multiclass.train', header=None, sep = '\\t')\n",
    "test= pd.read_csv('multiclass.test', header=None, sep = '\\t')\n",
    "num_train = train.shape[0]\n",
    "kfolds = 0.9\n",
    "\n",
    "\n",
    "X_train = train.ix[:int(kfolds * num_train),1:]\n",
    "y_train = train.ix[:int(kfolds * num_train),0]\n",
    "\n",
    "X_val = train.ix[int(kfolds * num_train):,1:]\n",
    "y_val = train.ix[int(kfolds * num_train):,0]\n",
    "\n",
    "X_test = test.ix[:,1:]\n",
    "y_test = test.ix[:,0]\n",
    "\n",
    "lgb_train = lgb.Dataset(X_train, y_train)\n",
    "lgb_test = lgb.Dataset(X_val, y_val)\n",
    "\n",
    "num_class = y_train.unique().max()+1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 设置初始参数(交叉验证的参数可以不设置)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "            'task': 'train',\n",
    "            'boosting_type': 'gbdt',\n",
    "            'objective': 'multiclass',\n",
    "            'metric': {'multi_error'},\n",
    "            'num_class': num_class,\n",
    "            'num_leaves': 80,\n",
    "            'feature_fraction': 0.9,\n",
    "            'bagging_fraction': 0.8,\n",
    "            'bagging_freq': 4,\n",
    "            'verbose': 0,\n",
    "            #'device':'gpu'\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 交叉验证过程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "min_merror = float('Inf')\n",
    "best_params = {}\n",
    "for learning_rate in [0.1]:\n",
    "    for num_boost_round in range(30, 31):\n",
    "        for max_depth in range(6, 8):\n",
    "            params['learning_rate'] = learning_rate\n",
    "            params['max_depth'] = max_depth\n",
    "            cv_results = lgb.cv(\n",
    "                            params,\n",
    "                            lgb_train,\n",
    "                            num_boost_round=num_boost_round,\n",
    "                            seed=42,\n",
    "                            nfold=3,\n",
    "                            metrics=['multi_error'],\n",
    "                            early_stopping_rounds=3\n",
    "                          )\n",
    "            mean_merror = pd.Series(cv_results['multi_error-mean']).min()\n",
    "            boost_rounds = pd.Series(cv_results['multi_error-mean']).argmin()\n",
    "            if mean_merror < min_merror:\n",
    "                min_merror = mean_merror\n",
    "                best_params['learning_rate'] = learning_rate\n",
    "                best_params['num_boost_round'] = boost_rounds\n",
    "                best_params['max_depth'] = max_depth\n",
    "\n",
    "# setting best params\n",
    "params['learning_rate'] = best_params['learning_rate']\n",
    "params['max_depth'] = best_params['max_depth']\n",
    "num_round = best_params['num_boost_round']\n",
    "\n",
    "# using lgb_test as valid_sets\n",
    "gbm = lgb.train(params,\n",
    "                lgb_train,\n",
    "                num_boost_round=num_round,\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.378\n"
     ]
    }
   ],
   "source": [
    "y_pred = gbm.predict(X_test)\n",
    "acc = accuracy_score(y_test, np.argmax(y_pred, axis=1))\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gbm.save_model('model.001')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 天池-蚂蚁金服：商场中精确定位用户所在店铺(部分关键代码)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "        sz = train.shape\n",
    "        kfolds = 0.8\n",
    "        train_X = train[:int(sz[0] * kfolds), :]\n",
    "        train_Y = label[:int(sz[0] * kfolds)]\n",
    "        \n",
    "        val_X = train[int(sz[0] * kfolds) : int(sz[0] * (kfolds + 0.1)), :]\n",
    "        val_Y = label[int(sz[0] * kfolds) : int( sz[0] * (kfolds + 0.1) )]\n",
    "        \n",
    "        test_X = train[int(sz[0] * (kfolds + 0.1 )):, :]\n",
    "        test_Y = label[int( sz[0] * (kfolds + 0.1) ):]\n",
    "\n",
    "        ltrain = lgb.Dataset(train_X, label=train_Y)\n",
    "        lval = lgb.Dataset(val_X, label=val_Y)\n",
    "\n",
    "        num_class = int( max(label) ) + 1\n",
    "\n",
    "        params = {  'task': 'train',\n",
    "                    'boosting_type': 'gbdt',\n",
    "                    'objective': 'multiclass',\n",
    "                    'metric': {'multi_error'},\n",
    "                    'num_class': num_class,\n",
    "                    'num_leaves': 64,\n",
    "                    'feature_fraction': 0.9,\n",
    "                    'bagging_fraction': 0.8,\n",
    "                    'bagging_freq': 4,\n",
    "                    'verbose':0,\n",
    "                    #'device': 'gpu'\n",
    "            }\n",
    "        num_boost_round = 30\n",
    "        model = lgb.train(  params,\n",
    "                            ltrain,\n",
    "                            num_boost_round,\n",
    "                            valid_sets=lval,\n",
    "                            early_stopping_rounds=5\n",
    "                            )\n",
    "        y_pred = model.predict(test_X, num_iteration=model.best_iteration)\n",
    "\n",
    "        acc = accuracy_score(test_Y, np.argmax(y_pred, axis=1))\n",
    "        print('Val acc is {}'.format(acc))\n",
    "        with open('test.csv', 'a') as f:\n",
    "            f.write(str(mall_file.split('.')[0])+','+str(acc)+'\\n')\n",
    "        model_path = model_dir+str( mall_file.split('.')[0] )+'.model'\n",
    "        model.save_model(model_path, num_iteration=model.best_iteration)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "思考：蚂蚁金服的代码中是在设定一组参数之后，根据验证集选择**num_boost_round**这个参数。早停止策略是独立于选参过程的，如果在train中设置了早停止策略，**注意模型并非在最佳num_boost_round处停止**，所以，在模型推断(inference)和模型持久化(persistence)时，要指定模型的最佳迭代次数**model.best_iteration**。\n",
    "\n",
    "和上述的交叉验证过程进行对比: 在训练数据较少的前提下，可以使用交叉验证充分利用已有数据进行参数选择。而上述过程其实是固定验证集的参数选择过程。一般来说，在给定模型超参数的前提下，可以通过比较最佳训练轮次对应的loss进行参数选择。在早停止策略下，比较最佳训练轮次附近的loss也是可以的。个人观点，当选择完超参数之后，需要在验证集上重新选择**num_boost_round**参数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
